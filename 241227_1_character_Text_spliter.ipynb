{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sn1r2nDqoJG_"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/data/appendix-keywords.txt\") as f:\n",
        "  file = f.read()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG1Et1C6rPiH",
        "outputId": "0abef2b1-a6ec-4582-a0ea-71dc808be46f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.TextIOWrapper name='/content/data/appendix-keywords.txt' mode='r' encoding='UTF-8'>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(file[:188])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPCviQRwrO2r",
        "outputId": "900f725f-6a7f-485e-9890-09866f6666bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semantic Search\n",
            "\n",
            "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
            "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
            "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   separator : 분할할 기준 , 기본 값 :\\n\\n\n",
        "*   chunk_size : 청크의 최대 크기 설정\n",
        "\n",
        "*   chunk_overlap : 인접한 청크 간 중복 허용\n",
        "*   length_function : 텍스트의 길이를 계산하는 함수\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IjsATYhgtZy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 문자를 구분하여 분할\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = '\\n\\n', # 텍스트 분할 기준\n",
        "    chunk_size = 210, # 문자 수\n",
        "    chunk_overlap  = 0, # 중복되는 문자 수 지정\n",
        "    length_function = len, # 텍스트의 길이 계산\n",
        ")\n"
      ],
      "metadata": {
        "id": "YcDkbfQbrUrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#텍스트를 청크로 분할\n",
        "texts = text_splitter.create_documents([file])\n",
        "print(len(texts[0].page_content)) #분할된 문서 개수 출력\n",
        "print(texts[0]) #분할된 문서 중 첫 번째 문서 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiUHyD2grUuh",
        "outputId": "a68a53ef-f747-46b2-b667-0c29b46943de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "197\n",
            "page_content='Semantic Search\n",
            "\n",
            "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
            "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
            "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
            "\n",
            "Embedding'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metadatas = [\n",
        "    {\"document\":1},\n",
        "    #{\"document\":2},\n",
        "]\n",
        "\n",
        "documents = text_splitter.create_documents(\n",
        "    [\n",
        "        file,\n",
        "        #file,\n",
        "    ],\n",
        "    metadatas=metadatas,\n",
        ")\n",
        "print(documents[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu1lXmaErUzB",
        "outputId": "565b5749-856d-4841-c73f-84719d65c8ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='Semantic Search\n",
            "\n",
            "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
            "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
            "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
            "\n",
            "Embedding' metadata={'document': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd39RVQtyc5z",
        "outputId": "01cd10e5-c161-4088-e5dc-5a2324382656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents[1].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QehOxCnhyV8V",
        "outputId": "aab5577a-9ccd-4c27-fc0c-4efc1333864f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'document': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " text_splitter.split_text(file)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "eeiEqhSHygVL",
        "outputId": "9cfb1f86-e3c7-4cfa-f7e4-a51eb22843d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Semantic Search\\n\\n정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\\n예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\\n\\nEmbedding'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 청크 사이즈 바꾸기"
      ],
      "metadata": {
        "id": "ONJsCh_XzDZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 문자를 구분하여 분할\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = '\\n\\n', # 텍스트 분할 기준\n",
        "    chunk_size = 205, # 문자 수\n",
        "    chunk_overlap  = 0, # 중복되는 문자 수 지정\n",
        "    length_function = len, # 텍스트의 길이 계산\n",
        ")\n"
      ],
      "metadata": {
        "id": "gkwF-Nz6zFa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#텍스트를 청크로 분할\n",
        "texts = text_splitter.create_documents([file])\n",
        "print(len(texts[0].page_content)) #분할된 문서 개수 출력\n",
        "print(texts[0]) #분할된 문서 중 첫 번째 문서 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d3USH2nzFhW",
        "outputId": "c00af7aa-c1f6-4533-a77c-9720997e6ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "197\n",
            "page_content='Semantic Search\n",
            "\n",
            "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
            "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
            "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
            "\n",
            "Embedding'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 파일 2개"
      ],
      "metadata": {
        "id": "-sJdQsf-6DEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/data/appendix-keywords.txt\") as f1:\n",
        "  file_1 = f1.read()\n",
        "with open(\"/content/data/자기소개서.txt\") as f2:\n",
        "  file_2 = f2.read()\n"
      ],
      "metadata": {
        "id": "AmtzXe2g6V80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 문자를 구분하여 분할\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = '\\n\\n', # 텍스트 분할 기준\n",
        "    chunk_size = 210, # 최대 문자 수\n",
        "    chunk_overlap  = 0, # 중복되는 문자 수 지정\n",
        "    length_function = len, # 텍스트의 길이 계산\n",
        ")\n"
      ],
      "metadata": {
        "id": "JHl4XfFCzFjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadatas = [\n",
        "    {\"document\":1},\n",
        "    {\"document\":2},\n",
        "]\n",
        "\n",
        "documents = text_splitter.create_documents(\n",
        "    [\n",
        "        file_1 ,\n",
        "        file_2 ,\n",
        "    ],\n",
        "    metadatas=metadatas,\n",
        ")\n",
        "print(documents[32])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lapLL4izFl1",
        "outputId": "112f2cf5-6ce6-4d5d-9de2-530e42776c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1151, which is longer than the specified 210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='저는 대학교에서 진행한 “차선 훼손 탐지” 프로젝트를 통해 컴퓨터 비전에 큰 관심을 가지게\n",
            "되었습니다. 도로 영상을 분석하여 차선을 탐지하고, 탐지한 차선의 훼손 상태를 분류하는 과\n",
            "정에서 영상 데이터의 중요성을 깨달았고, 다양한 이미지 전처리 및 딥러닝 모델을 적용하며\n",
            "흥미를 느꼈습니다. 이 경험을 통해 컴퓨터 비전 기술이 자율주행, 스마트 시티, 영상 분석 등\n",
            "여러 분야에서 중요한 역할을 한다는 확신을 가지게 되었습니다.\n",
            "또한, OpenCV를 활용한 영상 처리 및 YOLO 모델 기반의 객체 탐지 기술을 학습하였고, 이\n",
            "를 실제 데이터셋에 적용하여 연구한 경험이 있습니다. 컴퓨터 비전과 인공지능 기술은 빠르\n",
            "게 발전하고 있으며, 이를 활용해 다양한 문제를 해결할 수 있다는 점에서 매우 흥미롭고 도\n",
            "전적이라고 생각합니다.\n",
            "저는 어려운 상황에서도 불평없이 맡은 일을 묵묵히 해내는 성격입니다. 남에게 짐이 되는 상\n",
            "황을 못 견디기 때문에 ‘어려운 일이더라도 반드시 해야 한다면 해낸다’는 신념으로 일을 마\n",
            "무리합니다. 예의 바르고 긍정적인 성격 또한 저의 강점입니다. 팀원들과 원활한 업무를 이끌\n",
            "어내고, 활기를 불어넣는 역할을 합니다. 긍정적인 태도는 결국 좋은 결과로 이어진다고 믿습\n",
            "니다. 가끔 완벽하게 해야 한다는 생각에 부담을 느낄 때가 있지만, 이를 극복하기 위해 업무\n",
            "를 효율적으로 분배하고, 팀원들과 협업하여 균형을 맞추는 노력을 기울이고 있습니다. 또한,\n",
            "스스로의 기준이 높아 때로는 과도하게 신중해질 때가 있지만, 빠르고 효율적인 결정을 내리\n",
            "기 위해 우선 순위를 설정하고 개선해 나가고 있습니다.\n",
            "현재 인공지능학과 4학년에 재학 중이며, 학석사 연계 과정을 진행하고 있습니다. 과거에는\n",
            "자신을 다른 사람과 비교하며 과소평가했던 순간이 많았지만, 이번 비트 교육과정을 통해 자\n",
            "신감을 얻고, 제 모습을 극복하며 노력하고 싶습니다. 수료 후에는 현장에서 선배들로부터 배\n",
            "우고 실무에서 어떻게 일하는지 하나하나 익히는 것이 목표입니다. 또한, 석사 과정을 병행하\n",
            "며 회사의 프로젝트나 업무와 연계된 연구를 진행해보고 싶습니다. 현장에서 경험을 쌓고 연\n",
            "구를 병행하면, 회사에 실질적인 기여를 할 수 있을 것이며, 제 석사 과정에도 큰 도움이 될\n",
            "것입니다. 이번 교육 과정은 저에게 큰 도전이자 기회이므로 열심히 끝까지 노력할 것입니다.' metadata={'document': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 청크와 메타데이터 확인\n",
        "for idx, doc in enumerate(documents):\n",
        "    print(f\"Chunk {idx}:\")\n",
        "    print(f\"Content ({len(doc.page_content)} characters):\")\n",
        "    print(doc.page_content)\n",
        "    print(f\"Metadata: {doc.metadata}\")\n",
        "    print(\"-\" * 50)  # 구분선 추가\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YaN6Lf98-Ak",
        "outputId": "627afda2-b257-4b14-ff08-b78e136d9341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 0:\n",
            "Content (197 characters):\n",
            "Semantic Search\n",
            "\n",
            "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
            "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
            "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
            "\n",
            "Embedding\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 1:\n",
            "Content (169 characters):\n",
            "정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n",
            "예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n",
            "연관키워드: 자연어 처리, 벡터화, 딥러닝\n",
            "\n",
            "Token\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 2:\n",
            "Content (151 characters):\n",
            "정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\n",
            "예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\n",
            "연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
            "\n",
            "Tokenizer\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 3:\n",
            "Content (183 characters):\n",
            "정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\n",
            "예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\n",
            "연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
            "\n",
            "VectorStore\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 4:\n",
            "Content (147 characters):\n",
            "정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\n",
            "예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\n",
            "연관키워드: 임베딩, 데이터베이스, 벡터화\n",
            "\n",
            "SQL\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 5:\n",
            "Content (206 characters):\n",
            "정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을 수행할 수 있습니다.\n",
            "예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\n",
            "연관키워드: 데이터베이스, 쿼리, 데이터 관리\n",
            "\n",
            "CSV\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 6:\n",
            "Content (208 characters):\n",
            "정의: CSV(Comma-Separated Values)는 데이터를 저장하는 파일 형식으로, 각 데이터 값은 쉼표로 구분됩니다. 표 형태의 데이터를 간단하게 저장하고 교환할 때 사용됩니다.\n",
            "예시: 이름, 나이, 직업이라는 헤더를 가진 CSV 파일에는 홍길동, 30, 개발자와 같은 데이터가 포함될 수 있습니다.\n",
            "연관키워드: 데이터 형식, 파일 처리, 데이터 교환\n",
            "\n",
            "JSON\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 7:\n",
            "Content (194 characters):\n",
            "정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.\n",
            "예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\n",
            "연관키워드: 데이터 교환, 웹 개발, API\n",
            "\n",
            "Transformer\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 8:\n",
            "Content (188 characters):\n",
            "정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다. 이는 Attention 메커니즘을 기반으로 합니다.\n",
            "예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\n",
            "연관키워드: 딥러닝, 자연어 처리, Attention\n",
            "\n",
            "HuggingFace\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 9:\n",
            "Content (203 characters):\n",
            "정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록 돕습니다.\n",
            "예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\n",
            "연관키워드: 자연어 처리, 딥러닝, 라이브러리\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 10:\n",
            "Content (201 characters):\n",
            "Digital Transformation\n",
            "\n",
            "정의: 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영을 혁신하는 과정입니다. 이는 비즈니스 모델을 개선하고 디지털 기술을 통해 경쟁력을 높이는 데 중점을 둡니다.\n",
            "예시: 기업이 클라우드 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\n",
            "연관키워드: 혁신, 기술, 비즈니스 모델\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 11:\n",
            "Content (187 characters):\n",
            "Crawling\n",
            "\n",
            "정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\n",
            "예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\n",
            "연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\n",
            "\n",
            "Word2Vec\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 12:\n",
            "Content (201 characters):\n",
            "정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
            "예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
            "연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n",
            "LLM (Large Language Model)\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 13:\n",
            "Content (187 characters):\n",
            "정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\n",
            "예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\n",
            "연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\n",
            "\n",
            "FAISS (Facebook AI Similarity Search)\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 14:\n",
            "Content (189 characters):\n",
            "정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\n",
            "예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\n",
            "연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\n",
            "\n",
            "Open Source\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 15:\n",
            "Content (174 characters):\n",
            "정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\n",
            "예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\n",
            "연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\n",
            "\n",
            "Structured Data\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 16:\n",
            "Content (170 characters):\n",
            "정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된 데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색하고 분석할 수 있습니다.\n",
            "예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된 데이터의 예입니다.\n",
            "연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링\n",
            "\n",
            "Parser\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 17:\n",
            "Content (175 characters):\n",
            "정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분석이나 파일 데이터 처리에 사용됩니다.\n",
            "예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하는 것은 파싱의 한 예입니다.\n",
            "연관키워드: 구문 분석, 컴파일러, 데이터 처리\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 18:\n",
            "Content (50 characters):\n",
            "TF-IDF (Term Frequency-Inverse Document Frequency)\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 19:\n",
            "Content (186 characters):\n",
            "정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\n",
            "예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\n",
            "연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\n",
            "\n",
            "Deep Learning\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 20:\n",
            "Content (162 characters):\n",
            "정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\n",
            "예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\n",
            "연관키워드: 인공신경망, 머신러닝, 데이터 분석\n",
            "\n",
            "Schema\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 21:\n",
            "Content (169 characters):\n",
            "정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\n",
            "예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\n",
            "연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\n",
            "\n",
            "DataFrame\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 22:\n",
            "Content (182 characters):\n",
            "정의: DataFrame은 행과 열로 이루어진 테이블 형태의 데이터 구조로, 주로 데이터 분석 및 처리에 사용됩니다.\n",
            "예시: 판다스 라이브러리에서 DataFrame은 다양한 데이터 타입의 열을 가질 수 있으며, 데이터 조작과 분석을 용이하게 합니다.\n",
            "연관키워드: 데이터 분석, 판다스, 데이터 처리\n",
            "\n",
            "Attention 메커니즘\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 23:\n",
            "Content (207 characters):\n",
            "정의: Attention 메커니즘은 딥러닝에서 중요한 정보에 더 많은 '주의'를 기울이도록 하는 기법입니다. 이는 주로 시퀀스 데이터(예: 텍스트, 시계열 데이터)에서 사용됩니다.\n",
            "예시: 번역 모델에서 Attention 메커니즘은 입력 문장의 중요한 부분에 더 집중하여 정확한 번역을 생성합니다.\n",
            "연관키워드: 딥러닝, 자연어 처리, 시퀀스 모델링\n",
            "\n",
            "판다스 (Pandas)\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 24:\n",
            "Content (174 characters):\n",
            "정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조작 도구를 제공하는 라이브러리입니다. 이는 데이터 분석 작업을 효율적으로 수행할 수 있게 합니다.\n",
            "예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며, 다양한 분석을 수행할 수 있습니다.\n",
            "연관키워드: 데이터 분석, 파이썬, 데이터 처리\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 25:\n",
            "Content (39 characters):\n",
            "GPT (Generative Pretrained Transformer)\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 26:\n",
            "Content (197 characters):\n",
            "정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\n",
            "예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\n",
            "연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\n",
            "\n",
            "InstructGPT\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 27:\n",
            "Content (205 characters):\n",
            "정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록 설계되었습니다.\n",
            "예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.\n",
            "연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 28:\n",
            "Content (193 characters):\n",
            "Keyword Search\n",
            "\n",
            "정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를 찾는 과정입니다. 이는 대부분의 검색 엔진과 데이터베이스 시스템에서 기본적인 검색 방식으로 사용됩니다.\n",
            "예시: 사용자가 \"커피숍 서울\"이라고 검색하면, 관련된 커피숍 목록을 반환합니다.\n",
            "연관키워드: 검색 엔진, 데이터 검색, 정보 검색\n",
            "\n",
            "Page Rank\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 29:\n",
            "Content (186 characters):\n",
            "정의: 페이지 랭크는 웹 페이지의 중요도를 평가하는 알고리즘으로, 주로 검색 엔진 결과의 순위를 결정하는 데 사용됩니다. 이는 웹 페이지 간의 링크 구조를 분석하여 평가합니다.\n",
            "예시: 구글 검색 엔진은 페이지 랭크 알고리즘을 사용하여 검색 결과의 순위를 정합니다.\n",
            "연관키워드: 검색 엔진 최적화, 웹 분석, 링크 분석\n",
            "\n",
            "데이터 마이닝\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 30:\n",
            "Content (176 characters):\n",
            "정의: 데이터 마이닝은 대량의 데이터에서 유용한 정보를 발굴하는 과정입니다. 이는 통계, 머신러닝, 패턴 인식 등의 기술을 활용합니다.\n",
            "예시: 소매업체가 고객 구매 데이터를 분석하여 판매 전략을 수립하는 것은 데이터 마이닝의 예입니다.\n",
            "연관키워드: 빅데이터, 패턴 인식, 예측 분석\n",
            "\n",
            "멀티모달 (Multimodal)\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 31:\n",
            "Content (215 characters):\n",
            "정의: 멀티모달은 여러 종류의 데이터 모드(예: 텍스트, 이미지, 소리 등)를 결합하여 처리하는 기술입니다. 이는 서로 다른 형식의 데이터 간의 상호 작용을 통해 보다 풍부하고 정확한 정보를 추출하거나 예측하는 데 사용됩니다.\n",
            "예시: 이미지와 설명 텍스트를 함께 분석하여 더 정확한 이미지 분류를 수행하는 시스템은 멀티모달 기술의 예입니다.\n",
            "연관키워드: 데이터 융합, 인공지능, 딥러닝\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 32:\n",
            "Content (1151 characters):\n",
            "저는 대학교에서 진행한 “차선 훼손 탐지” 프로젝트를 통해 컴퓨터 비전에 큰 관심을 가지게\n",
            "되었습니다. 도로 영상을 분석하여 차선을 탐지하고, 탐지한 차선의 훼손 상태를 분류하는 과\n",
            "정에서 영상 데이터의 중요성을 깨달았고, 다양한 이미지 전처리 및 딥러닝 모델을 적용하며\n",
            "흥미를 느꼈습니다. 이 경험을 통해 컴퓨터 비전 기술이 자율주행, 스마트 시티, 영상 분석 등\n",
            "여러 분야에서 중요한 역할을 한다는 확신을 가지게 되었습니다.\n",
            "또한, OpenCV를 활용한 영상 처리 및 YOLO 모델 기반의 객체 탐지 기술을 학습하였고, 이\n",
            "를 실제 데이터셋에 적용하여 연구한 경험이 있습니다. 컴퓨터 비전과 인공지능 기술은 빠르\n",
            "게 발전하고 있으며, 이를 활용해 다양한 문제를 해결할 수 있다는 점에서 매우 흥미롭고 도\n",
            "전적이라고 생각합니다.\n",
            "저는 어려운 상황에서도 불평없이 맡은 일을 묵묵히 해내는 성격입니다. 남에게 짐이 되는 상\n",
            "황을 못 견디기 때문에 ‘어려운 일이더라도 반드시 해야 한다면 해낸다’는 신념으로 일을 마\n",
            "무리합니다. 예의 바르고 긍정적인 성격 또한 저의 강점입니다. 팀원들과 원활한 업무를 이끌\n",
            "어내고, 활기를 불어넣는 역할을 합니다. 긍정적인 태도는 결국 좋은 결과로 이어진다고 믿습\n",
            "니다. 가끔 완벽하게 해야 한다는 생각에 부담을 느낄 때가 있지만, 이를 극복하기 위해 업무\n",
            "를 효율적으로 분배하고, 팀원들과 협업하여 균형을 맞추는 노력을 기울이고 있습니다. 또한,\n",
            "스스로의 기준이 높아 때로는 과도하게 신중해질 때가 있지만, 빠르고 효율적인 결정을 내리\n",
            "기 위해 우선 순위를 설정하고 개선해 나가고 있습니다.\n",
            "현재 인공지능학과 4학년에 재학 중이며, 학석사 연계 과정을 진행하고 있습니다. 과거에는\n",
            "자신을 다른 사람과 비교하며 과소평가했던 순간이 많았지만, 이번 비트 교육과정을 통해 자\n",
            "신감을 얻고, 제 모습을 극복하며 노력하고 싶습니다. 수료 후에는 현장에서 선배들로부터 배\n",
            "우고 실무에서 어떻게 일하는지 하나하나 익히는 것이 목표입니다. 또한, 석사 과정을 병행하\n",
            "며 회사의 프로젝트나 업무와 연계된 연구를 진행해보고 싶습니다. 현장에서 경험을 쌓고 연\n",
            "구를 병행하면, 회사에 실질적인 기여를 할 수 있을 것이며, 제 석사 과정에도 큰 도움이 될\n",
            "것입니다. 이번 교육 과정은 저에게 큰 도전이자 기회이므로 열심히 끝까지 노력할 것입니다.\n",
            "Metadata: {'document': 2}\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#separator 변경\n"
      ],
      "metadata": {
        "id": "99tUCHtC-vXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 문자를 구분하여 분할\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = '\\n', # 텍스트 분할 기준\n",
        "    chunk_size = 210, # 최대 문자 수\n",
        "    chunk_overlap  = 0, # 중복되는 문자 수 지정\n",
        "    length_function = len, # 텍스트의 길이 계산\n",
        ")\n"
      ],
      "metadata": {
        "id": "1P0_Hh18-4dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadatas = [\n",
        "    {\"document\":1},\n",
        "    {\"document\":2},\n",
        "]\n",
        "\n",
        "documents = text_splitter.create_documents(\n",
        "    [\n",
        "        file_1 ,\n",
        "        file_2 ,\n",
        "    ],\n",
        "    metadatas=metadatas,\n",
        ")\n",
        "print(documents[32])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TWNPKJH-4mH",
        "outputId": "9a7eb41e-c367-4b19-ee95-8cfdde57c7a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='저는 대학교에서 진행한 “차선 훼손 탐지” 프로젝트를 통해 컴퓨터 비전에 큰 관심을 가지게\n",
            "되었습니다. 도로 영상을 분석하여 차선을 탐지하고, 탐지한 차선의 훼손 상태를 분류하는 과\n",
            "정에서 영상 데이터의 중요성을 깨달았고, 다양한 이미지 전처리 및 딥러닝 모델을 적용하며\n",
            "흥미를 느꼈습니다. 이 경험을 통해 컴퓨터 비전 기술이 자율주행, 스마트 시티, 영상 분석 등' metadata={'document': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 청크와 메타데이터 확인\n",
        "for idx, doc in enumerate(documents):\n",
        "    print(f\"Chunk {idx}:\")\n",
        "    print(f\"Content ({len(doc.page_content)} characters):\")\n",
        "    print(doc.page_content)\n",
        "    print(f\"Metadata: {doc.metadata}\")\n",
        "    print(\"-\" * 50)  # 구분선 추가"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEznZFCk-4p4",
        "outputId": "7860ca51-61b4-479b-e036-6508ba08b125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 0:\n",
            "Content (195 characters):\n",
            "Semantic Search\n",
            "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
            "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
            "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
            "Embedding\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 1:\n",
            "Content (168 characters):\n",
            "정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n",
            "예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n",
            "연관키워드: 자연어 처리, 벡터화, 딥러닝\n",
            "Token\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 2:\n",
            "Content (150 characters):\n",
            "정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\n",
            "예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\n",
            "연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
            "Tokenizer\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 3:\n",
            "Content (182 characters):\n",
            "정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\n",
            "예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\n",
            "연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
            "VectorStore\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 4:\n",
            "Content (146 characters):\n",
            "정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\n",
            "예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\n",
            "연관키워드: 임베딩, 데이터베이스, 벡터화\n",
            "SQL\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 5:\n",
            "Content (205 characters):\n",
            "정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을 수행할 수 있습니다.\n",
            "예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\n",
            "연관키워드: 데이터베이스, 쿼리, 데이터 관리\n",
            "CSV\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 6:\n",
            "Content (207 characters):\n",
            "정의: CSV(Comma-Separated Values)는 데이터를 저장하는 파일 형식으로, 각 데이터 값은 쉼표로 구분됩니다. 표 형태의 데이터를 간단하게 저장하고 교환할 때 사용됩니다.\n",
            "예시: 이름, 나이, 직업이라는 헤더를 가진 CSV 파일에는 홍길동, 30, 개발자와 같은 데이터가 포함될 수 있습니다.\n",
            "연관키워드: 데이터 형식, 파일 처리, 데이터 교환\n",
            "JSON\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 7:\n",
            "Content (193 characters):\n",
            "정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.\n",
            "예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\n",
            "연관키워드: 데이터 교환, 웹 개발, API\n",
            "Transformer\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 8:\n",
            "Content (187 characters):\n",
            "정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다. 이는 Attention 메커니즘을 기반으로 합니다.\n",
            "예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\n",
            "연관키워드: 딥러닝, 자연어 처리, Attention\n",
            "HuggingFace\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 9:\n",
            "Content (203 characters):\n",
            "정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록 돕습니다.\n",
            "예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\n",
            "연관키워드: 자연어 처리, 딥러닝, 라이브러리\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 10:\n",
            "Content (209 characters):\n",
            "Digital Transformation\n",
            "정의: 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영을 혁신하는 과정입니다. 이는 비즈니스 모델을 개선하고 디지털 기술을 통해 경쟁력을 높이는 데 중점을 둡니다.\n",
            "예시: 기업이 클라우드 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\n",
            "연관키워드: 혁신, 기술, 비즈니스 모델\n",
            "Crawling\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 11:\n",
            "Content (176 characters):\n",
            "정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\n",
            "예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\n",
            "연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\n",
            "Word2Vec\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 12:\n",
            "Content (201 characters):\n",
            "정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
            "예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
            "연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n",
            "LLM (Large Language Model)\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 13:\n",
            "Content (186 characters):\n",
            "정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\n",
            "예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\n",
            "연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\n",
            "FAISS (Facebook AI Similarity Search)\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 14:\n",
            "Content (188 characters):\n",
            "정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\n",
            "예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\n",
            "연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\n",
            "Open Source\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 15:\n",
            "Content (173 characters):\n",
            "정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\n",
            "예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\n",
            "연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\n",
            "Structured Data\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 16:\n",
            "Content (169 characters):\n",
            "정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된 데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색하고 분석할 수 있습니다.\n",
            "예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된 데이터의 예입니다.\n",
            "연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링\n",
            "Parser\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 17:\n",
            "Content (175 characters):\n",
            "정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분석이나 파일 데이터 처리에 사용됩니다.\n",
            "예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하는 것은 파싱의 한 예입니다.\n",
            "연관키워드: 구문 분석, 컴파일러, 데이터 처리\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 18:\n",
            "Content (192 characters):\n",
            "TF-IDF (Term Frequency-Inverse Document Frequency)\n",
            "정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\n",
            "예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 19:\n",
            "Content (205 characters):\n",
            "연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\n",
            "Deep Learning\n",
            "정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\n",
            "예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\n",
            "연관키워드: 인공신경망, 머신러닝, 데이터 분석\n",
            "Schema\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 20:\n",
            "Content (168 characters):\n",
            "정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\n",
            "예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\n",
            "연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\n",
            "DataFrame\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 21:\n",
            "Content (181 characters):\n",
            "정의: DataFrame은 행과 열로 이루어진 테이블 형태의 데이터 구조로, 주로 데이터 분석 및 처리에 사용됩니다.\n",
            "예시: 판다스 라이브러리에서 DataFrame은 다양한 데이터 타입의 열을 가질 수 있으며, 데이터 조작과 분석을 용이하게 합니다.\n",
            "연관키워드: 데이터 분석, 판다스, 데이터 처리\n",
            "Attention 메커니즘\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 22:\n",
            "Content (206 characters):\n",
            "정의: Attention 메커니즘은 딥러닝에서 중요한 정보에 더 많은 '주의'를 기울이도록 하는 기법입니다. 이는 주로 시퀀스 데이터(예: 텍스트, 시계열 데이터)에서 사용됩니다.\n",
            "예시: 번역 모델에서 Attention 메커니즘은 입력 문장의 중요한 부분에 더 집중하여 정확한 번역을 생성합니다.\n",
            "연관키워드: 딥러닝, 자연어 처리, 시퀀스 모델링\n",
            "판다스 (Pandas)\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 23:\n",
            "Content (174 characters):\n",
            "정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조작 도구를 제공하는 라이브러리입니다. 이는 데이터 분석 작업을 효율적으로 수행할 수 있게 합니다.\n",
            "예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며, 다양한 분석을 수행할 수 있습니다.\n",
            "연관키워드: 데이터 분석, 파이썬, 데이터 처리\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 24:\n",
            "Content (197 characters):\n",
            "GPT (Generative Pretrained Transformer)\n",
            "정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\n",
            "예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 25:\n",
            "Content (139 characters):\n",
            "연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\n",
            "InstructGPT\n",
            "정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록 설계되었습니다.\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 26:\n",
            "Content (119 characters):\n",
            "예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.\n",
            "연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\n",
            "Keyword Search\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 27:\n",
            "Content (176 characters):\n",
            "정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를 찾는 과정입니다. 이는 대부분의 검색 엔진과 데이터베이스 시스템에서 기본적인 검색 방식으로 사용됩니다.\n",
            "예시: 사용자가 \"커피숍 서울\"이라고 검색하면, 관련된 커피숍 목록을 반환합니다.\n",
            "연관키워드: 검색 엔진, 데이터 검색, 정보 검색\n",
            "Page Rank\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 28:\n",
            "Content (185 characters):\n",
            "정의: 페이지 랭크는 웹 페이지의 중요도를 평가하는 알고리즘으로, 주로 검색 엔진 결과의 순위를 결정하는 데 사용됩니다. 이는 웹 페이지 간의 링크 구조를 분석하여 평가합니다.\n",
            "예시: 구글 검색 엔진은 페이지 랭크 알고리즘을 사용하여 검색 결과의 순위를 정합니다.\n",
            "연관키워드: 검색 엔진 최적화, 웹 분석, 링크 분석\n",
            "데이터 마이닝\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 29:\n",
            "Content (175 characters):\n",
            "정의: 데이터 마이닝은 대량의 데이터에서 유용한 정보를 발굴하는 과정입니다. 이는 통계, 머신러닝, 패턴 인식 등의 기술을 활용합니다.\n",
            "예시: 소매업체가 고객 구매 데이터를 분석하여 판매 전략을 수립하는 것은 데이터 마이닝의 예입니다.\n",
            "연관키워드: 빅데이터, 패턴 인식, 예측 분석\n",
            "멀티모달 (Multimodal)\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 30:\n",
            "Content (190 characters):\n",
            "정의: 멀티모달은 여러 종류의 데이터 모드(예: 텍스트, 이미지, 소리 등)를 결합하여 처리하는 기술입니다. 이는 서로 다른 형식의 데이터 간의 상호 작용을 통해 보다 풍부하고 정확한 정보를 추출하거나 예측하는 데 사용됩니다.\n",
            "예시: 이미지와 설명 텍스트를 함께 분석하여 더 정확한 이미지 분류를 수행하는 시스템은 멀티모달 기술의 예입니다.\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 31:\n",
            "Content (24 characters):\n",
            "연관키워드: 데이터 융합, 인공지능, 딥러닝\n",
            "Metadata: {'document': 1}\n",
            "--------------------------------------------------\n",
            "Chunk 32:\n",
            "Content (204 characters):\n",
            "저는 대학교에서 진행한 “차선 훼손 탐지” 프로젝트를 통해 컴퓨터 비전에 큰 관심을 가지게\n",
            "되었습니다. 도로 영상을 분석하여 차선을 탐지하고, 탐지한 차선의 훼손 상태를 분류하는 과\n",
            "정에서 영상 데이터의 중요성을 깨달았고, 다양한 이미지 전처리 및 딥러닝 모델을 적용하며\n",
            "흥미를 느꼈습니다. 이 경험을 통해 컴퓨터 비전 기술이 자율주행, 스마트 시티, 영상 분석 등\n",
            "Metadata: {'document': 2}\n",
            "--------------------------------------------------\n",
            "Chunk 33:\n",
            "Content (203 characters):\n",
            "여러 분야에서 중요한 역할을 한다는 확신을 가지게 되었습니다.\n",
            "또한, OpenCV를 활용한 영상 처리 및 YOLO 모델 기반의 객체 탐지 기술을 학습하였고, 이\n",
            "를 실제 데이터셋에 적용하여 연구한 경험이 있습니다. 컴퓨터 비전과 인공지능 기술은 빠르\n",
            "게 발전하고 있으며, 이를 활용해 다양한 문제를 해결할 수 있다는 점에서 매우 흥미롭고 도\n",
            "전적이라고 생각합니다.\n",
            "Metadata: {'document': 2}\n",
            "--------------------------------------------------\n",
            "Chunk 34:\n",
            "Content (203 characters):\n",
            "저는 어려운 상황에서도 불평없이 맡은 일을 묵묵히 해내는 성격입니다. 남에게 짐이 되는 상\n",
            "황을 못 견디기 때문에 ‘어려운 일이더라도 반드시 해야 한다면 해낸다’는 신념으로 일을 마\n",
            "무리합니다. 예의 바르고 긍정적인 성격 또한 저의 강점입니다. 팀원들과 원활한 업무를 이끌\n",
            "어내고, 활기를 불어넣는 역할을 합니다. 긍정적인 태도는 결국 좋은 결과로 이어진다고 믿습\n",
            "Metadata: {'document': 2}\n",
            "--------------------------------------------------\n",
            "Chunk 35:\n",
            "Content (183 characters):\n",
            "니다. 가끔 완벽하게 해야 한다는 생각에 부담을 느낄 때가 있지만, 이를 극복하기 위해 업무\n",
            "를 효율적으로 분배하고, 팀원들과 협업하여 균형을 맞추는 노력을 기울이고 있습니다. 또한,\n",
            "스스로의 기준이 높아 때로는 과도하게 신중해질 때가 있지만, 빠르고 효율적인 결정을 내리\n",
            "기 위해 우선 순위를 설정하고 개선해 나가고 있습니다.\n",
            "Metadata: {'document': 2}\n",
            "--------------------------------------------------\n",
            "Chunk 36:\n",
            "Content (201 characters):\n",
            "현재 인공지능학과 4학년에 재학 중이며, 학석사 연계 과정을 진행하고 있습니다. 과거에는\n",
            "자신을 다른 사람과 비교하며 과소평가했던 순간이 많았지만, 이번 비트 교육과정을 통해 자\n",
            "신감을 얻고, 제 모습을 극복하며 노력하고 싶습니다. 수료 후에는 현장에서 선배들로부터 배\n",
            "우고 실무에서 어떻게 일하는지 하나하나 익히는 것이 목표입니다. 또한, 석사 과정을 병행하\n",
            "Metadata: {'document': 2}\n",
            "--------------------------------------------------\n",
            "Chunk 37:\n",
            "Content (152 characters):\n",
            "며 회사의 프로젝트나 업무와 연계된 연구를 진행해보고 싶습니다. 현장에서 경험을 쌓고 연\n",
            "구를 병행하면, 회사에 실질적인 기여를 할 수 있을 것이며, 제 석사 과정에도 큰 도움이 될\n",
            "것입니다. 이번 교육 과정은 저에게 큰 도전이자 기회이므로 열심히 끝까지 노력할 것입니다.\n",
            "Metadata: {'document': 2}\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fBavooe0-4s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M3KxNcpp-4u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z9r_aj1S-4xX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}